# Supervised learning

Given a training set, learn a good predictor.

- regression problem: target variable continuous
- classification problem: discrete

## Linear regression

$$h(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 = \sum_{i=0}^n\theta_i\x_i=\theta^Tx$$

cost function

$$J(\theta)=\frac{1}{2}\sum_{i=1}^m(h_\theta(x^{(i)})-y_{(i)})^2.$$

### LMS algorithm

Gradient descent algorithm: start with some guess, update $\theta$ by partial derivative multiplied by learning rate $\alpha$.

Linear regression problem has only one global optima, therefore gradiant desent always converges.

batch v.s incremental gradient desent, when the training set is large, latter is preferred.




